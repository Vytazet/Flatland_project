{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5HNZR2UcJj3Q",
        "KMIsT-AxJnTf",
        "rDyzUlvTfivW",
        "ctGZtEJGOqE8",
        "x_P3mgUaYmHI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VMPV1ub98dFZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from keras.models import Model\n",
        "from keras.layers import Conv2D, Dense, BatchNormalization, Input\n",
        "from keras.layers import Flatten, MaxPooling2D, Activation, RandomRotation\n",
        "from keras.layers import AveragePooling2D, InputLayer, SpatialDropout2D \n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.load('flatland_train.npz')\n",
        "X = data['X']\n",
        "y = data['y'].astype(int)\n",
        "\n",
        "y[y != 0] -= 2    # Correct labels so that triangle is mapped to class 1\n",
        "X = X / 255.      # Scale down to range [0, 1]\n",
        "\n",
        "\n",
        "# model.save('model.h5')"
      ],
      "metadata": {
        "id": "400wKxCKmjqW"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
      ],
      "metadata": {
        "id": "BaC190ICnmFN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple different models"
      ],
      "metadata": {
        "id": "7DpkOoWH2nzU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First model\n",
        "A couple of convolutional layers as well as a maxpooling layer."
      ],
      "metadata": {
        "id": "5HNZR2UcJj3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(InputLayer(input_shape=[50, 50, 1]))\n",
        "\n",
        "  model.add(Conv2D(128, kernel_size=(5, 5), strides=2))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(4, 4)))\n",
        "\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"relu\"))\n",
        "\n",
        "\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1000, activation=\"relu\"))\n",
        "  model.add(keras.layers.Dropout(0.2))\n",
        "  model.add(Dense(1000, activation=\"relu\"))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer='sgd',\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "32_rXuV_9yt3"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second model\n",
        "Imitation of Lenet-5 architecture."
      ],
      "metadata": {
        "id": "KMIsT-AxJnTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(InputLayer(input_shape=[50, 50, 1]))\n",
        "  model.add(Conv2D(6, kernel_size=(5, 5)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"tanh\"))\n",
        "  \n",
        "  model.add(AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  model.add(Conv2D(16, kernel_size=(5, 5)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"tanh\"))\n",
        "\n",
        "  model.add(AveragePooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  model.add(Conv2D(120, kernel_size=(5, 5)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation(\"tanh\"))\n",
        "\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(84, activation=\"tanh\"))\n",
        "  model.add(keras.layers.Dropout(0.4))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.Adam(3e-4),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "XPrv_luuJiRA"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Third model\n",
        "Added RandomRotation layer and spatial dropout."
      ],
      "metadata": {
        "id": "rDyzUlvTfivW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(InputLayer(input_shape=[50, 50, 1]))\n",
        "  model.add(RandomRotation(factor=0.5, fill_mode='constant', fill_value=0.0))\n",
        "\n",
        "  model.add(Conv2D(128, kernel_size=(5, 5), strides=2, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(SpatialDropout2D(0.2))\n",
        "\n",
        "\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(SpatialDropout2D(0.2))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1000, activation=\"relu\"))\n",
        "  model.add(keras.layers.Dropout(0.5))\n",
        "  model.add(Dense(1000, activation=\"relu\"))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "K5HouKi_fmcl"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fourth model\n",
        "Trying the dilation rate parameter."
      ],
      "metadata": {
        "id": "ctGZtEJGOqE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = keras.models.Sequential()\n",
        "  model.add(InputLayer(input_shape=[50, 50, 1]))\n",
        "  model.add(RandomRotation(factor=0.5, fill_mode='constant', fill_value=0.0))\n",
        "\n",
        "  model.add(Conv2D(96, kernel_size=(5, 5), dilation_rate=2, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(SpatialDropout2D(0.2))\n",
        "  \n",
        "  model.add(MaxPooling2D(pool_size=(3, 3), strides=3))\n",
        "\n",
        "  model.add(Conv2D(128, kernel_size=(3, 3), dilation_rate=2, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(SpatialDropout2D(0.1))\n",
        "  \n",
        "  model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation=\"relu\"))\n",
        "  model.add(keras.layers.Dropout(0.5))\n",
        "  model.add(Dense(1024, activation=\"relu\"))\n",
        "  model.add(Dense(5, activation=\"softmax\"))\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer='sgd',\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "jV8xYrdCOo_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Different representation of the third model\n",
        "Reduced number of weights from layers."
      ],
      "metadata": {
        "id": "x_P3mgUaYmHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  inp = Input(shape=(50, 50, 1))\n",
        "\n",
        "  out = RandomRotation(factor=0.5, fill_mode='constant', fill_value=0.0)(inp)\n",
        "  out = Conv2D(64, kernel_size=(7, 7), strides=2, activation='relu')(out)\n",
        "  out = BatchNormalization()(out)\n",
        "  out = SpatialDropout2D(0.2)(out)\n",
        "\n",
        "  out = Conv2D(64, kernel_size=(5, 5), activation='relu')(out)\n",
        "  out = BatchNormalization()(out)\n",
        "  out = SpatialDropout2D(0.2)(out)\n",
        "\n",
        "  out = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "\n",
        "  out = Conv2D(64, kernel_size=(3, 3), activation='relu')(out)\n",
        "  out = BatchNormalization()(out)\n",
        "\n",
        "  out = MaxPooling2D(pool_size=(2, 2))(out)\n",
        "\n",
        "  out = Conv2D(64, kernel_size=(3, 3), activation='relu')(out)\n",
        "  out = BatchNormalization()(out)\n",
        "\n",
        "  out = Flatten()(out)\n",
        "  out = Dense(600, activation=\"relu\")(out)\n",
        "  out = keras.layers.Dropout(0.5)(out)\n",
        "  out = Dense(5, activation=\"softmax\")(out)\n",
        "  \n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "so8wK0LYYq-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best model (for now)\n",
        "Switched some layers around."
      ],
      "metadata": {
        "id": "87pR7cTRNieE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  inp = Input(shape=(50, 50, 1))\n",
        "\n",
        "  out = RandomRotation(factor=0.5, fill_mode='constant', fill_value=0.0)(inp)\n",
        "  out = Conv2D(64, kernel_size=(7, 7), strides=2, activation='relu')(out)\n",
        "  out = BatchNormalization()(out)\n",
        "  out = SpatialDropout2D(0.2)(out)\n",
        "  \n",
        "  out = Conv2D(128, kernel_size=(5, 5), activation='relu')(out)\n",
        "  out = BatchNormalization()(out)\n",
        "  out = SpatialDropout2D(0.2)(out)\n",
        "\n",
        "  out = MaxPooling2D(pool_size=(3, 3))(out)\n",
        "\n",
        "  out = Conv2D(64, kernel_size=(3, 3), activation='relu')(out)\n",
        "  out = BatchNormalization()(out)\n",
        "  out = SpatialDropout2D(0.1)(out)\n",
        "\n",
        "  out = Conv2D(32, kernel_size=(3, 3), activation='relu')(out)\n",
        "  out = BatchNormalization()(out)\n",
        "\n",
        "  out = Flatten()(out)\n",
        "  out = Dense(512, activation=\"relu\")(out)\n",
        "  out = keras.layers.Dropout(0.5)(out)\n",
        "  out = Dense(5, activation=\"softmax\")(out)\n",
        "  \n",
        "  model = Model(inputs=inp, outputs=out)\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "KuZE8FJcNnMV"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trials"
      ],
      "metadata": {
        "id": "H4DBcaKVJrV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "t--iezP7Awgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model.fit(X_train, y_train, batch_size=16, epochs=30, \n",
        "                 validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-exl-0nhdMH",
        "outputId": "c950f34e-7be0-4429-bed2-1862d3420c46"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "375/375 [==============================] - 4s 8ms/step - loss: 1.3825 - accuracy: 0.4090 - val_loss: 1.8269 - val_accuracy: 0.1447\n",
            "Epoch 2/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 1.0128 - accuracy: 0.5690 - val_loss: 0.7823 - val_accuracy: 0.6525\n",
            "Epoch 3/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.7563 - accuracy: 0.7003 - val_loss: 0.4189 - val_accuracy: 0.8717\n",
            "Epoch 4/30\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.5866 - accuracy: 0.7878 - val_loss: 0.4475 - val_accuracy: 0.8438\n",
            "Epoch 5/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.4961 - accuracy: 0.8262 - val_loss: 0.3471 - val_accuracy: 0.9028\n",
            "Epoch 6/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.4158 - accuracy: 0.8730 - val_loss: 0.2106 - val_accuracy: 0.9625\n",
            "Epoch 7/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.3768 - accuracy: 0.8810 - val_loss: 0.2026 - val_accuracy: 0.9670\n",
            "Epoch 8/30\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.3324 - accuracy: 0.8975 - val_loss: 0.1610 - val_accuracy: 0.9808\n",
            "Epoch 9/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2786 - accuracy: 0.9252 - val_loss: 0.1569 - val_accuracy: 0.9778\n",
            "Epoch 10/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2760 - accuracy: 0.9230 - val_loss: 0.1511 - val_accuracy: 0.9803\n",
            "Epoch 11/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2421 - accuracy: 0.9380 - val_loss: 0.1406 - val_accuracy: 0.9815\n",
            "Epoch 12/30\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2264 - accuracy: 0.9455 - val_loss: 0.1429 - val_accuracy: 0.9812\n",
            "Epoch 13/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2190 - accuracy: 0.9448 - val_loss: 0.1729 - val_accuracy: 0.9622\n",
            "Epoch 14/30\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.2092 - accuracy: 0.9507 - val_loss: 0.1440 - val_accuracy: 0.9772\n",
            "Epoch 15/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.2007 - accuracy: 0.9523 - val_loss: 0.1552 - val_accuracy: 0.9743\n",
            "Epoch 16/30\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1942 - accuracy: 0.9573 - val_loss: 0.1375 - val_accuracy: 0.9818\n",
            "Epoch 17/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1966 - accuracy: 0.9533 - val_loss: 0.1522 - val_accuracy: 0.9758\n",
            "Epoch 18/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1892 - accuracy: 0.9575 - val_loss: 0.1316 - val_accuracy: 0.9843\n",
            "Epoch 19/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1807 - accuracy: 0.9618 - val_loss: 0.1282 - val_accuracy: 0.9835\n",
            "Epoch 20/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1771 - accuracy: 0.9638 - val_loss: 0.1266 - val_accuracy: 0.9847\n",
            "Epoch 21/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1631 - accuracy: 0.9700 - val_loss: 0.1245 - val_accuracy: 0.9847\n",
            "Epoch 22/30\n",
            "375/375 [==============================] - 4s 10ms/step - loss: 0.1673 - accuracy: 0.9682 - val_loss: 0.1196 - val_accuracy: 0.9855\n",
            "Epoch 23/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1663 - accuracy: 0.9655 - val_loss: 0.1355 - val_accuracy: 0.9808\n",
            "Epoch 24/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1644 - accuracy: 0.9647 - val_loss: 0.1330 - val_accuracy: 0.9827\n",
            "Epoch 25/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1593 - accuracy: 0.9670 - val_loss: 0.1254 - val_accuracy: 0.9840\n",
            "Epoch 26/30\n",
            "375/375 [==============================] - 3s 9ms/step - loss: 0.1579 - accuracy: 0.9702 - val_loss: 0.1277 - val_accuracy: 0.9825\n",
            "Epoch 27/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1701 - accuracy: 0.9628 - val_loss: 0.1215 - val_accuracy: 0.9843\n",
            "Epoch 28/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1676 - accuracy: 0.9688 - val_loss: 0.1324 - val_accuracy: 0.9810\n",
            "Epoch 29/30\n",
            "375/375 [==============================] - 3s 7ms/step - loss: 0.1591 - accuracy: 0.9713 - val_loss: 0.1211 - val_accuracy: 0.9852\n",
            "Epoch 30/30\n",
            "375/375 [==============================] - 2s 7ms/step - loss: 0.1481 - accuracy: 0.9743 - val_loss: 0.1187 - val_accuracy: 0.9847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(loss.history).plot()"
      ],
      "metadata": {
        "id": "96wc0XKcwD6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_test).argmax(axis=1)\n",
        "failures = X_test[pred != y_test]\n",
        "index = np.arange(0, len(y_test))[pred != y_test]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkZXmNP76-tH",
        "outputId": "1d2564a7-18a3-48dd-ec3b-61de1c9af7a2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "125/125 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "failures.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EUPXzBR7bHO",
        "outputId": "189fe3d1-707d-408c-d69f-d94132596837"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(61, 50, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(4, 4, figsize=(12,16))\n",
        "\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    ax.imshow(failures[i], cmap='gray')\n",
        "    ax.set_axis_off()\n",
        "    ax.set_title(f'P: {pred[index[i]]}, T: {y_test[index[i]]}')"
      ],
      "metadata": {
        "id": "FCTdWxWo7CjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning"
      ],
      "metadata": {
        "id": "dKS0kh3YUXp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobile_net = keras.applications.MobileNet(weights='imagenet', include_top=False,\n",
        "                                          input_shape=(50, 50, 3))\n",
        "\n",
        "mobile_net.trainable = False\n",
        "    \n",
        "inputs = keras.layers.Input(shape=(50, 50, 3))\n",
        "embedding = mobile_net(inputs, training=False)\n",
        "output = keras.layers.Flatten()(embedding)\n",
        "output = keras.layers.Dense(5, activation='softmax')(output)\n",
        "model = keras.models.Model(inputs=inputs, outputs=output)\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='sgd', loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "LeXiT5TeUWgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new_train = np.repeat(X_train[..., None], 3, axis=3)\n",
        "X_new_test = np.repeat(X_test[..., None], 3, axis=3)"
      ],
      "metadata": {
        "id": "Ifx3fTW5bQrr"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_new_train, y_train, validation_data=(X_new_test, y_test), batch_size=16, \n",
        "          epochs=30)"
      ],
      "metadata": {
        "id": "gyIqtvQFaIaS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}